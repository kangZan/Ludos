# Ludos v0.1.0 改造后设计点评文档

> 审阅日期：2026-02-06
> 审阅基准：需求概述.md + 工程要求.md + 实际代码实现

---

## 一、设计意图还原

Ludos 的设计目标是构建一个**角色驱动**（而非作者驱动）的叙事推演系统。核心设计哲学是：

> "行动结果不由行动者或主持人决定，而由下一个受影响角色的反应来逆向确定。"

这一哲学贯穿整个架构，是系统的灵魂所在。

---

## 二、架构设计优势

### 2.1 三阶段流水线——清晰且正确

```
初始化（Initialization）→ 自主推演循环（Deduction Loop）→ 润色（Polishing）
```

**优势分析**：

| 阶段 | 职责边界 | 评价 |
|---|---|---|
| 初始化 | 纲要 → 客观事实 + 角色档案 → 记忆 seed | 将非结构化输入转为结构化数据，隔离了 LLM 解析的不确定性 |
| 推演循环 | 场景播报 → 行动顺序 → 逐角色决策 → 回合评估 → 结束检测 | 循环结构完整，各节点职责单一 |
| 润色 | 原始日志 → 文学叙事 | 与推演解耦，不影响逻辑正确性 |

**核心优势**：三阶段之间的数据契约清晰——初始化产出 `ObjectiveFacts` + `CharacterDossier`，推演循环产出 `ActionPack` 日志，润色消费日志。阶段间不存在隐式依赖。

### 2.2 认知红绿灯——三层防御的分层策略

需求要求"信息严格隔离"，设计方案将其分解为三个独立防御层：

| 层级 | 实现位置 | 机制 |
|---|---|---|
| **结构过滤层** | `info_filter.py` | 构建角色上下文时，物理剥离 `inner_reasoning`，仅保留公开可观察的行动 |
| **提示词约束层** | `prompts.py` CHARACTER_DECISION | "你只能引用【我所知道的】中列出的信息" |
| **事后验证层** | `validators.py` validate_no_info_leakage | 扫描输出中是否引用了其他角色的秘密关键词 |

**优势**：
- 不依赖单一防线，但改造后**第一层已足以从根源消除泄露**——角色 LLM 的输入中物理上不存在其他角色的私有数据
- 第二层提示词约束进一步强化角色自律
- 第三层事后验证作为冗余安全网存在（当前未接入，但因前两层的架构级保障，不构成实际风险）
- `TaggedInfo` 的 `visibility` + `known_by` 标注实现了细粒度的信息可见性控制

**关键评价**：改造将角色记忆从全局状态剥离到独立 `.mem.txt` 文件后，认知红绿灯从"三层都必须工作"变成了"第一层已彻底阻断数据通道"。这是**从系统层面解决问题**的正确思路——不是靠检测和修复泄露，而是消灭泄露发生的可能性。

**完整数据流验证**：
| 角色 A 的 LLM 收到什么 | 是否含角色 B 的私有信息 |
|---|---|
| `filter_visible_actions()` 过滤后的行动 | `inner_reasoning` 始终为空字符串 |
| 自己的 `.mem.txt`（稳定记忆/工作记忆/目标/秘密） | 只读自己的文件 |
| `public_log` 增量（`format_public_action_line`） | 不含 `inner_reasoning` |
| 场景描述 | 纯客观信息 |
| 上轮自己的内心想法 | `last_inner_thoughts[自己的ID]` |

**结论：不存在任何数据路径使角色 A 获取角色 B 的 `inner_reasoning`、秘密、目标或私人理解。**

**设计启示**：这是 AI Agent 系统中"防御性编程"的优秀范例——不信任 LLM 的自律性，通过系统架构**在数据通道层面**强制约束，而非依赖事后检测。

### 2.3 角色记忆自管——从全局状态中剥离

改造前（推测）：角色目标、秘密、压力值存在于全局 `DeductionState` 中。
改造后：每个角色维护独立的 `.mem.txt` 文件，包含：

```
[STATE]       → 读取偏移等技术状态
[GOALS]       → 目标列表及自评状态
[SECRETS]     → 秘密及关键词
[PRESSURE]    → 各秘密的压力值
[STABLE]      → 稳定记忆（身份、背景）
[WORKING]     → 工作记忆（可追加/可压缩）
[SELF_EVAL]   → 角色自评（目标进展）
```

**优势**：
1. **信息隔离强化**：主持人无法通过读取全局状态"意外"获取角色私有信息
2. **可调试性**：运行中可直接打开 `data/characters/{session_id}/{角色}.mem.txt` 查看角色认知状态
3. **角色自评**：目标状态由角色自行评估更新（`[SELF_EVAL]`），而非主持人判定，符合"角色驱动"理念
4. **记忆压缩**：`MEMORY_SUMMARY` 机制允许 LLM 自主决定何时压缩工作记忆

**设计意义**：这是本次改造最重要的架构决策。它将"角色自主性"从概念落实到了数据架构层面。

### 2.4 公共/私有日志分离

```
logs/
├── session_{id}.public.log       ← 所有角色可见的公开行为
├── session_{id}_{角色A}.raw.log  ← 角色A的完整行为（含inner_reasoning）
└── session_{id}_{角色B}.raw.log  ← 角色B的完整行为
```

**优势**：
- 公共日志作为角色间的"信息总线"——角色通过增量读取公共日志获知他人的公开行为
- 私有日志保留完整决策过程，支持事后分析和润色阶段使用
- `InteractionLogWriter` 追加写入，确保运行时日志不丢失

### 2.5 秘密压力系统——有机的秘密暴露

设计特点：
- **关键词触发**：从对话中匹配秘密关键词，增加压力
- **直接寻址加成**：如果说话者直接针对秘密持有者，压力增量更大
- **自然衰减**：没有触发时压力自动下降
- **角色自决**：达到阈值后仅注入"说漏嘴警告"，由角色自行决定是否暴露

**设计智慧**：
1. 避免了"硬触发"——不是压力值到 100 就自动暴露，而是给角色选择权
2. 衰减机制防止压力单调递增导致必然暴露
3. 关键词匹配是一种低成本的语义近似，比全文语义匹配更可控

### 2.6 非数值化冲突解决——提示词层面的约束

```
错误示范："造成50点伤害"
正确示范："刀刃堪堪划过衣袖，带起一道浅浅的血痕"
```

设计选择：通过 `POLISHER_NARRATIVE` 提示词的正例/反例约束，而非在代码中检测和拒绝数值表达。

**优势**：简洁，利用 LLM 的 in-context learning 能力。
**风险**：提示词约束不是强保证（见劣势部分）。

### 2.7 结束条件多层判定

```python
1. ending_direction_met → 剧本结局方向达成
2. should_end (moderator) → 主持人评估应结束
3. protagonist goals resolved → 主角目标解决
4. all goals resolved → 所有目标解决
5. max_rounds → 硬性上限
```

**优势**：
- 优先级递降，最具叙事意义的条件排在最前
- 主角目标优先于全员目标，避免配角目标拖延剧情
- `max_rounds` 作为兜底防止无限循环

### 2.8 提示词模板设计

`prompts.py` 中四个模板（场景播报、行动顺序、回合评估、角色决策）均采用：
- 明确的角色定位（"你是...的主持人"）
- 结构化的输入占位符
- 半结构化的输出格式要求
- 明确的禁令规则

**特别好的设计**：`CHARACTER_DECISION` 模板将角色的"稳定记忆"、"工作记忆"、"公共广播增量"三段分开注入，让角色能区分长期认知和即时信息。

---

## 三、架构设计劣势与风险

### 3.1 子图设计未落地——模块化承诺未兑现

**现状**：代码定义了四个独立子图——

| 子图 | 文件 | 是否使用 |
|---|---|---|
| `build_initialization_graph()` | `initialization.py` | 未使用 |
| `build_deduction_loop_graph()` | `deduction_loop.py` | 未使用 |
| `build_polishing_graph()` | `polishing.py` | 未使用 |
| `build_character_subgraph()` | `character_subgraph.py` | 未使用 |

`orchestrator.py` 将所有节点平铺在单个 `StateGraph` 中。

**损失**：
1. **状态隔离丧失**：LangGraph 子图可以有独立的状态 schema，避免不同阶段的状态字段互相污染。当前 `DeductionState` 包含 52 行字段定义，涵盖全部三阶段。
2. **可测试性降低**：无法单独编译和测试推演循环子图。
3. `character_subgraph.py` 的验证重试循环未接入——但**需强调**：由于改造后的私有记忆架构已在数据通道层面消除了信息泄露可能，第三层验证在新架构下是冗余安全网，**并非安全缺陷**。子图未接入的实际损失主要是结构校验（`validate_action_pack`）缺失，以及代码整洁性问题。

**根因推测**：LangGraph 的 `add_subgraph` API 在嵌套状态映射上有一定复杂度，可能在迭代中遇到困难后改为平铺方案。

### 3.2 文件系统耦合——记忆协议的双刃剑

文件制记忆虽然可调试，但引入了多个问题：

| 问题 | 影响 |
|---|---|
| LangGraph 检查点无法覆盖文件状态 | 从检查点恢复运行时，图状态回滚但文件记忆不回滚，导致状态不一致 |
| 角色决策函数内含文件 I/O | `decide_action` 直接 `open()` 读取公共日志，无法纯函数测试 |
| 并发风险 | 多角色同时读写同一公共日志文件（虽然当前串行执行，但设计上未防护） |
| 跨进程不安全 | 如果未来支持分布式角色执行，文件协议将成为瓶颈 |

**建议方向**：将文件操作封装为 `MemoryStore` 抽象，实现可替换后端（文件/Redis/内存 mock）。

### 3.3 公共日志文件偏移量——脆弱的通信机制

角色通过 `last_public_offset` 追踪已读位置，从公共日志文件增量读取：

```python
f.seek(memory.last_public_offset)
public_delta = f.read()
memory.last_public_offset = f.tell()
```

**脆弱点**：
1. 如果公共日志文件被截断或重写，偏移量失效
2. 偏移量持久化在角色记忆文件中，如果记忆文件损坏，角色会重读或跳过日志
3. 此机制将"角色获知公共信息"与"文件系统操作"强耦合

**更健壮的替代方案**：将公共广播作为图状态的一部分传递，通过回合号索引增量。

### 3.4 主持人评估的信息来源限制不够彻底

`assess_round_node` 中：

```python
char_goals: dict[str, list[dict]] = {}  # 空字典
```

主持人评估时不读取角色目标（正确），但在 `check_end_node` 中：

```python
character_goals=load_goals_map(
    f"data/characters/{state.get('session_id','default')}",
    state.get("character_ids", []),
)
```

结束检测**直接读取角色记忆文件中的目标状态**。这意味着系统层面会读取角色私有数据来判断结束条件，虽然不暴露给主持人 LLM，但在架构上打破了"信息隔离"的纯粹性。

**争议**：这可以被视为"系统层面的元判断"而非主持人行为，但值得在设计文档中明确说明。

### 3.5 缺少角色并行执行能力

当前推演循环中角色严格串行执行：

```
角色A决策 → 角色B决策 → 角色C决策 → 回合评估
```

**后果**：
- 后行动的角色始终能看到先行动角色的行为，这引入了"先行劣势"
- 对于"同时行动"场景（如武斗中双方同时出招），无法建模
- 性能上，N 个角色需要 N 次串行 LLM 调用

**需求回顾**：需求文档提到"多个角色同时发起时，可由主持人选择一个作为开始事件"，暗示并行行动是预期行为，但实现为串行。

### 3.6 提示词约束非数值化——无系统级保障

非数值化冲突解决完全依赖提示词：

```
- 错误示范："造成50点伤害"
- 正确示范："刀刃堪堪划过衣袖"
```

**风险**：LLM 可能在推演阶段（而非润色阶段）输出数值化内容。当前无系统级检测机制。

**建议**：可在 `validate_action_pack` 中增加正则检测，拒绝含"HP"、"伤害值"、"攻击力"等数值化表达的输出。

### 3.7 回合评估 GOAL_ASSESSMENTS 基于角色自评

设计方案让回合评估中的目标进展基于"角色自评输出"而非主持人独立判断：

```
注意：goal_assessments 可基于角色自评输出，不要自行"纠正"角色目标状态
```

**矛盾**：如果主持人不纠正角色自评，那么评估结果完全取决于角色（LLM）的自我判断。LLM 可能对"目标达成"过于乐观或保守，导致结束条件判定不准确。

**设计张力**：这是"角色自主性"与"系统可控性"之间的固有矛盾。当前设计偏向自主性，这是有意识的取舍，但需要注意极端情况（如角色永远不认为目标失败，导致推演无限进行）。

### 3.8 润色阶段直接读取角色记忆文件

```python
# polisher.py
for mem_file in sorted(memory_path.glob("*.mem.txt")):
    content = mem_file.read_text(encoding="utf-8")
```

润色器直接遍历文件系统获取角色内部状态。这意味着：
1. 润色器的输入不可控——它看到的是运行结束时的最终记忆状态，而非每个交互时刻的记忆快照
2. 如果记忆文件在运行中被压缩（`MEMORY_SUMMARY`），早期的工作记忆可能已丢失

**更好的方案**：润色器应消费 raw log 文件（已包含 `inner_reasoning`）+ 初始角色档案，而非运行时记忆。

### 3.9 LLM 后端适配硬编码

```python
def _supports_structured_output() -> bool:
    base_url = settings.llm_base_url.lower()
    model = settings.llm_model.lower()
    if "deepseek" in base_url or "deepseek" in model:
        return False
    return True
```

**问题**：通过字符串匹配判断后端能力，不可扩展。新增 LLM 后端（如 Ollama、vLLM、Anthropic）都需要修改此函数。

**建议**：改为配置项 `llm_supports_structured_output: bool = True`。

---

## 四、需求覆盖度评估

| 需求项 | 实现状态 | 评价 |
|---|---|---|
| 三阶段架构 | 完成 | 结构清晰 |
| 认知红绿灯 | 架构级完成 | 第一层（结构过滤 + 私有记忆隔离）已彻底阻断泄露通道；第三层为冗余安全网，未接入不影响安全性 |
| 秘密压力系统 | 完成（角色侧） | 独立工具侧未调用 |
| 非数值化冲突 | 提示词层完成 | 无系统级检测 |
| 角色自主决策 | 完成 | 核心机制运作良好 |
| 主持人中立记录 | 完成 | `assess_round_node` 仅看公共行为 |
| "下一角色决定结果" | 完成 | 通过串行执行 + visible actions 实现 |
| 原始交互日志 | 完成 | 运行时落盘 |
| 润色叙事文本 | 完成 | 文学化提示词设计好 |
| 人工审核档案 | 框架在（review_dossiers_node）| 实际为 pass-through |
| 插件化工具 | 完成 | 注册 + 环境变量加载 |
| 状态持久化 | 完成 | InMemory + Postgres 双后端 |
| 流式输出 | 完成 | astream + 增量打印 |
| 健康检查 | 完成 | CLI --health + LLM 连通性 |
| 角色小动作（计划中） | 未实现 | 已记录为下一步 |

**覆盖率**：已实现需求项的完整覆盖约 **90%**。缺口主要在人工审核环节（pass-through）和角色小动作（计划中）。认知红绿灯通过架构级改造（私有记忆自管）实现了比原始三层设计更强的信息隔离保障。

---

## 五、设计模式识别

### 5.1 已采用的模式

| 模式 | 实例 | 评价 |
|---|---|---|
| **状态机** | LangGraph StateGraph + conditional edges | 核心架构，使用正确 |
| **累积器** | `Annotated[list, operator.add]` | 日志和评估的追加语义 |
| **策略** | Checkpointer（InMemory vs Postgres） | 环境适配 |
| **注册表** | `tools/registry.py` | 工具动态注册 |
| **降级** | `_coerce_minimal_initialization` | LLM 解析失败时的兜底 |
| **观察者** | `astream` + event dispatch | 流式输出通知 |
| **单例** | LLM client, prompt cache | 存在但有测试隔离问题 |

### 5.2 可考虑引入的模式

| 模式 | 适用场景 |
|---|---|
| **抽象工厂** | 记忆存储后端（文件/Redis/Mock）|
| **中介者** | 替代文件偏移量的公共广播机制 |
| **命令** | 角色行动包的统一处理管道 |
| **模板方法** | 统一 `format_action_line` 系列函数 |

---

## 六、与 LangGraph 生态的契合度

### 6.1 良好契合

- `StateGraph` + `TypedDict` 状态定义
- `add_conditional_edges` 实现循环和分支
- `InMemorySaver` / `AsyncPostgresSaver` 检查点
- `astream(stream_mode="updates")` 流式事件
- 中断/续传（`__interrupt__` 处理）

### 6.2 未充分利用

| LangGraph 能力 | 当前状态 | 建议 |
|---|---|---|
| 子图嵌套 | 定义了但未使用 | 接入，利用独立状态 schema |
| `add_messages` reducer | 声明了但未使用 | `messages` 字段始终为空，可移除 |
| Tool calling | 未使用 | 可将 `filter_visible_actions` 等注册为 LangGraph Tool |
| Human-in-the-loop | 框架在但为 pass-through | 接入实际审核逻辑 |
| Send API (Map-Reduce) | 未使用 | 可用于角色并行决策 |

---

## 七、总结

### 核心设计亮点

1. **"角色驱动"理念贯穿到数据架构**——记忆自管、目标自评、秘密自决
2. **认知红绿灯三层防御**——不信任 LLM 的自律性，系统级强制隔离
3. **半结构化协议**——务实应对 LLM 输出的不确定性
4. **公共/私有日志分离**——信息流控有清晰的物理边界
5. **多层结束条件**——叙事意义优先于硬性规则

### 核心设计风险

1. **子图未接入**——模块化设计意图未兑现，存在死代码（但不构成安全风险——私有记忆架构已消除信息泄露通道）
2. **文件系统耦合**——与 LangGraph 检查点机制不兼容
3. **串行执行限制**——无法建模同时行动场景
4. **角色自评可靠性**——结束条件依赖 LLM 的自我判断

### 改造价值评估

| 维度 | 改造前 | 改造后 | 变化 |
|---|---|---|---|
| 可运行性 | 纯文档 | 可端到端运行 | 从 0 到 1 |
| 信息隔离 | 概念 | 结构过滤 + 提示词 + 记忆分离 | 多层实现 |
| 可调试性 | 无 | 文件记忆 + 结构化日志 + 流式输出 | 显著提升 |
| 可扩展性 | 无 | 工具插件 + 配置驱动 | 基础就绪 |
| 测试覆盖 | 无 | 核心工具 6 个测试文件 | 从 0 到 ~60% |
| LangGraph 利用 | 无 | 状态图 + 检查点 + 流式 | 基础到位，子图待接入 |

**总体评价**：改造成功地将一个概念设计转化为可运行系统。架构选择务实、核心机制创新。最关键的改造成就是**将角色记忆从全局状态剥离到独立文件**——这一决策从数据通道层面彻底消除了信息泄露的可能性，比原设计中的"三层验证"方案更为彻底和可靠。子图定义未接入属于代码整洁问题，而非安全风险。下一步应优先处理文件系统耦合（与 LangGraph 检查点兼容性）和压力系统双重实现的统一。
